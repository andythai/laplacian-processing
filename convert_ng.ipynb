{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 3rd party libraries\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# OME Zarr\n",
    "import zarr\n",
    "from dask.array import from_zarr, moveaxis\n",
    "from numcodecs import Blosc\n",
    "from ome_zarr.writer import write_image\n",
    "from ome_zarr.io import parse_url\n",
    "\n",
    "# Our libraries\n",
    "import tif_to_ome\n",
    "from cellAnalysis.cell_detection import createShardedPointAnnotation, readSectionTif\n",
    "import ng_utils\n",
    "import cors_webserver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tif_to_zarr(img_dir, out_dir):\n",
    "    \"\"\" Given an image directory and an output directory, \n",
    "    this function converts the tiff files into a zarr group.\n",
    "\n",
    "    Args:\n",
    "        img_dir (_type_): a string representing the path to the image directory.\n",
    "        out_dir (_type_): a string representing the path to the output directory.\n",
    "\n",
    "    Returns:\n",
    "        _type_: a integer value of 0 if the conversion is successful, else 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # List of image files that needs to be stacked.\n",
    "        fns = natsorted(glob.glob(img_dir + \"/*.tif\", recursive=True))\n",
    "        \n",
    "        # Load the tiff directories\n",
    "        print(fns)\n",
    "\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "\n",
    "        # Path to zarr group\n",
    "        zarr_path = os.path.join(out_dir, \"data.zarr\")\n",
    "\n",
    "        # Create an ome zarr group\n",
    "        ome_path = os.path.join(out_dir, \"ome.zarr\")\n",
    "        image = tif_to_ome.readTifSection(str(fns[0]))\n",
    "        w,h = image.shape\n",
    "\n",
    "        # Write into zarr group\n",
    "        zarr_file = zarr.open(zarr_path,shape=(len(fns), w, h), chunks = (1, w, h),  dtype='u2')\n",
    "        Parallel(n_jobs=5, verbose=13)(delayed(tif_to_ome.readTifWrapper)(i, zarr_file, fn) for i, fn in enumerate(fns))\n",
    "        print(zarr_file)\n",
    "\n",
    "        # Read into a dask array\n",
    "        dask_arr = from_zarr(zarr_file)\n",
    "        print(dask_arr.shape)\n",
    "\n",
    "        # Write to a ome Zarr group\n",
    "        compressor = Blosc(cname=\"zstd\", clevel=5, shuffle=Blosc.SHUFFLE)\n",
    "        store = parse_url(ome_path, mode=\"w\").store\n",
    "        zarr_grp = zarr.open(store=store)\n",
    "        z = 5\n",
    "        w = 500\n",
    "        h = 500\n",
    "        #write_image(dask_arr, group = zarr_grp,axes=\"zxy\",storage_options=dict(chunks=(z, w, h)))\n",
    "        write_image(dask_arr, group=zarr_grp, axes=\"zyx\", storage_options=dict(chunks=(z, w, h), compressor=compressor))\n",
    "\n",
    "        print(\"OME zarr conversion done!\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "def convert_tif_to_zarr_rgb(img_dir_ch0, img_dir_ch1, img_dir_ch2, out_dir):\n",
    "    \"\"\" Given an image directory and an output directory, \n",
    "    this function converts the tiff files into a zarr group.\n",
    "\n",
    "    Args:\n",
    "        img_dir (_type_): a string representing the path to the image directory.\n",
    "        out_dir (_type_): a string representing the path to the output directory.\n",
    "\n",
    "    Returns:\n",
    "        _type_: a integer value of 0 if the conversion is successful, else 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # List of image files that needs to be stacked.\n",
    "        fns0 = natsorted(glob.glob(img_dir_ch0 + \"/*.tif\", recursive=True))[:5]\n",
    "        fns1 = natsorted(glob.glob(img_dir_ch1 + \"/*.tif\", recursive=True))[:5]\n",
    "        fns2 = natsorted(glob.glob(img_dir_ch2 + \"/*.tif\", recursive=True))[:5]\n",
    "        \n",
    "        assert len(fns0) == len(fns1) == len(fns2), \"Mismatch in number of files between channels\"\n",
    "\n",
    "        # Load the tiff directories\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "\n",
    "        # Path to zarr group\n",
    "        zarr_path = os.path.join(out_dir, \"data.zarr\")\n",
    "\n",
    "        # Create an ome zarr group\n",
    "        ome_path = os.path.join(out_dir, \"ome.zarr\")\n",
    "        image = tif_to_ome.readTifSection(str(fns0[0]))\n",
    "        w,h = image.shape\n",
    "\n",
    "        # Write into zarr group\n",
    "        zarr_file = zarr.open(zarr_path,shape=(len(fns0), w, h, 3), chunks = (1, w, h, 3),  dtype='u2')\n",
    "        \n",
    "        def read_and_stack(i, zarr_file, fn0, fn1, fn2):\n",
    "            img0 = tif_to_ome.readTifSection(fn0)\n",
    "            img1 = tif_to_ome.readTifSection(fn1)\n",
    "            img2 = tif_to_ome.readTifSection(fn2)\n",
    "            rgb_image = np.stack((img0, img1, img2), axis=-1)\n",
    "            zarr_file[i, :, :, :] = rgb_image\n",
    "        \n",
    "        Parallel(n_jobs=5, verbose=13)(delayed(read_and_stack)(i, zarr_file, fn0, fn1, fn2) for i, (fn0, fn1, fn2) in enumerate(zip(fns0, fns1, fns2)))\n",
    "        print(zarr_file)\n",
    "\n",
    "        # Read into a dask array\n",
    "        dask_arr = from_zarr(zarr_file)\n",
    "        print(dask_arr.shape)\n",
    "        dask_arr = moveaxis(dask_arr, -1, 0)\n",
    "        print(dask_arr.shape)\n",
    "\n",
    "        # Write to a ome Zarr group\n",
    "        compressor = Blosc(cname=\"zstd\", clevel=5, shuffle=Blosc.SHUFFLE)\n",
    "        store = parse_url(ome_path, mode=\"w\").store\n",
    "        zarr_grp = zarr.open(store=store)\n",
    "        z = 5\n",
    "        w = 500\n",
    "        h = 500\n",
    "        #write_image(dask_arr, group = zarr_grp,axes=\"zxy\",storage_options=dict(chunks=(z, w, h)))\n",
    "        write_image(dask_arr, group=zarr_grp, axes=\"czyx\", storage_options=dict(chunks=(3, z, w, h), compressor=compressor))\n",
    "\n",
    "        print(\"OME zarr conversion done!\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to ome zarr \n",
    "input_path = \"../B0039_stitched/stitched_ch2/\"\n",
    "ome_zarr_output_path = \"../B0039_stitched/stitched_counted/output/B0039_ome.zarr_2\"\n",
    "\n",
    "# Convert them to ome.zarr directories\n",
    "if GENERATE:\n",
    "    convert_tif_to_zarr(input_path, ome_zarr_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to ome zarr  RGB\n",
    "input_path0 = \"../B0039_stitched/stitched_ch0/\"\n",
    "input_path1 = \"../B0039_stitched/stitched_ch1/\"\n",
    "input_path2 = \"../B0039_stitched/stitched_ch2/\"\n",
    "ome_zarr_output_path = \"../B0039_stitched/stitched_counted/output/B0039_rgb_ome.zarr\"\n",
    "\n",
    "# Convert them to ome.zarr directories\n",
    "if GENERATE:\n",
    "    convert_tif_to_zarr_rgb(input_path0, input_path1, input_path2, ome_zarr_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert points to neuroglancer shards\n",
    "inputpoints_path = \"../B0039_stitched/stitched_counted/output/inputpoints.txt\"\n",
    "ng_points_path = \"../B0039_stitched/stitched_counted/output/\"\n",
    "\n",
    "# Convert points to neuroglancer format\n",
    "if GENERATE:\n",
    "    inputpoints = np.loadtxt(inputpoints_path, skiprows=2)\n",
    "    createShardedPointAnnotation(inputpoints, ng_points_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start up local server\n",
    "\n",
    "\n",
    "# Generate neuroglancer URL\n",
    "# https://xulabtexera.anat.uci.edu/\n",
    "\n",
    "# Open up neuroglancer URL in browser and visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0001_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0002_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0003_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0004_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0005_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0006_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0007_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0008_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0009_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0010_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0011_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0012_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0013_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0014_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0015_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0016_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0017_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0018_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0019_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0020_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0021_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0022_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0023_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0024_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0025_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0026_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0027_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0028_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0029_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0030_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0031_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0032_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0033_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0034_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0035_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0036_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0037_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0038_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0039_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0040_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0041_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0042_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0043_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0044_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0045_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0046_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0047_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0048_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0049_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0050_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0051_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0052_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0053_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0054_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0055_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0056_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0057_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0058_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0059_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0060_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0061_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0062_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0063_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0064_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0065_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0066_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0067_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0068_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0069_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0070_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0071_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0072_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0073_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0074_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0075_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0076_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0077_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0078_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0079_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0080_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0081_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0082_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0083_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0084_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0085_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0086_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0087_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0088_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0089_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0090_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0091_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0092_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0093_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0094_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0095_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0096_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0097_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0098_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0099_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0100_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0101_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0102_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0103_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0104_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0105_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0106_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0107_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0108_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0109_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0110_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0111_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0112_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0113_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0114_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0115_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0116_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0117_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0118_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0119_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0120_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0121_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0122_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0123_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0124_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0125_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0126_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0127_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0128_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0129_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0130_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0131_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0132_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0133_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0134_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0135_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0136_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0137_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0138_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0139_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0140_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0141_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0142_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0143_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0144_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0145_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0146_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0147_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0148_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0149_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0150_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0151_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0152_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0153_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0154_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0155_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0156_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0157_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0158_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0159_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0160_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0161_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0162_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0163_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0164_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0165_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0166_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0167_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0168_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0169_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0170_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0171_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0172_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0173_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0174_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0175_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0176_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0177_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0178_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0179_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0180_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0181_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0182_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0183_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0184_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0185_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0186_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0187_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0188_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0189_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0190_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0191_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0192_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0193_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0194_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0195_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0196_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0197_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0198_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0199_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0200_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0201_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0202_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0203_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0204_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0205_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0206_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0207_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0208_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0209_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0210_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0211_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0212_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0213_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0214_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0215_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0216_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0217_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0218_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0219_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0220_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0221_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0222_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0223_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0224_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0225_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0226_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0227_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0228_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0229_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0230_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0231_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0232_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0233_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0234_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0235_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0236_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0237_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0238_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0239_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0240_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0241_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0242_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0243_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0244_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0245_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0246_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0247_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0248_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0249_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0250_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0251_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0252_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0253_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0254_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0255_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0256_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0257_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0258_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0259_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0260_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0261_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0262_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0263_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0264_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0265_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0266_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0267_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0268_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0269_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0270_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0271_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0272_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0273_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0274_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0275_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0276_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0277_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0278_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0279_1_0.tif', '../B0039_stitched/stitched_ch0\\\\230628_B0039_PG_U01_280-0280_1_0.tif']\n",
      "120\n",
      "Reading cell data\n",
      "[[2804. 8025.]\n",
      " [3979. 8568.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ng_utils import ng_SingleSectionLocalViewer\n",
    "import webbrowser\n",
    "\n",
    "\n",
    "# Taken from cell detection preview code\n",
    "section = 120\n",
    "imgfiles = natsorted(glob.glob(os.path.join(input_path0, \"*.tif\"), recursive=True))\n",
    "print(imgfiles)\n",
    "print(section)\n",
    "\n",
    "imgfile  = imgfiles[section]\n",
    "image = readSectionTif(imgfile)\n",
    "print(\"Reading cell data\")\n",
    "\n",
    "cells = np.loadtxt(inputpoints_path, skiprows=2)\n",
    "cells = cells[cells[:, 0] == section, 1:]\n",
    "print(cells)\n",
    "\n",
    "viewer = ng_SingleSectionLocalViewer(image, cells)\n",
    "webbrowser.open(viewer.get_viewer_url())\n",
    "#input(\"Press any key to continue\")\n",
    "#viewer = ng_SingleSectionLocalViewer(image, cells, viewer)\n",
    "#webbrowser.open(viewer.get_viewer_url())\n",
    "#input(\"Press any key to exit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../B0039_stitched/stitched_ch0/*.tif'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(input_path0, \"*.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from cell detection preview code\n",
    "def main():\n",
    "    args = arg_parser().parse_args()\n",
    "    img_dir = Path(args.img_dir)\n",
    "    channel = args.channel\n",
    "    section = args.section\n",
    "    threshold  = args.threshold\n",
    "\n",
    "\n",
    "    input_points_file = img_dir/\"inputpoints.txt\"\n",
    "\n",
    "    imgfiles = natsorted(glob.glob(os.path.join(img_dir,\"**/*1_{}.tif\".format(channel)), recursive=True))\n",
    "    print(img_dir/'**/*1_{}.tif'.format(channel))\n",
    "    print(section)\n",
    "    if section==-1:\n",
    "        cells = Parallel(n_jobs=-4, verbose=13)(delayed(get_cell_locations)(img_file, intensity_threshold=threshold, index =i) for i, img_file in enumerate(imgfiles))\n",
    "        points = np.vstack(cells)\n",
    "        np.savetxt(input_points_file, points , \"%d %d %d\", header = \"point\\n\"+str(cells.shape[0]), comments =\"\")\n",
    "        createShardedPointAnnotation(points,img_dir)\n",
    "\n",
    "    else:\n",
    "        imgfile  = imgfiles[section]\n",
    "        image = readSectionTif(imgfile)\n",
    "        print(\"Detecting Cells\")\n",
    "        cells = get_cell_locations(image, intensity_threshold=threshold)\n",
    "        viewer = ng_SingleSectionLocalViewer(image, cells)\n",
    "        webbrowser.open(viewer.get_viewer_url())\n",
    "        input(\"Press any key to continue\")\n",
    "        viewer = ng_SingleSectionLocalViewer(image, cells, viewer)\n",
    "        webbrowser.open(viewer.get_viewer_url())\n",
    "        input(\"Press any key to exit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.parse\n",
    "\n",
    "\n",
    "def to_url(path, param):\n",
    "    # If no parameters are passed, use default settings\n",
    "    # TODO: Determine param format\n",
    "    if not param:\n",
    "        param = {\n",
    "            'starting_position': [0.0000013717664160139975,\n",
    "                                  4307.64990234375,\n",
    "                                  5821.93310546875],\n",
    "            'x_mm': 1.25,\n",
    "            'y_mm': 1.25,\n",
    "            'z_mm': 50,\n",
    "            'projection_scale': 13107.2,\n",
    "            'cross_section_scale': 16.068429538550138,\n",
    "        }\n",
    "    # Create grayscale template layer\n",
    "    mm_dict = get_mm_dict(param[\"z_mm\"],\n",
    "                          param[\"y_mm\"],\n",
    "                          param[\"x_mm\"])\n",
    "    template_layer = get_template_layer(template_src=path,\n",
    "                                        mm_dict=mm_dict,\n",
    "                                        public_name=\"ome.zarr_neuroglancer\")\n",
    "    url = get_final_url(image_layer_list=[template_layer],\n",
    "                        template_layer=template_layer,\n",
    "                        starting_position=param['starting_position'],\n",
    "                        mm_dict=mm_dict,\n",
    "                        projection_scale=param['projection_scale'],\n",
    "                        cross_section_scale=param['cross_section_scale'])\n",
    "    print(url)\n",
    "    return url\n",
    "\n",
    "\"\"\"\n",
    "class ProcessTupleOperator(UDFOperatorV2):\n",
    "\n",
    "    @overrides\n",
    "    def process_tuple(self, tuple_: Tuple, port: int) -> Iterator[Optional[TupleLike]]:\n",
    "        # host = \"https://kiwi1.ics.uci.edu/neuroglancer-ftp\"\n",
    "        # path = tuple_['ome_zarr_path'].replace(\"/workspace/texera/core/amber/user-resources/files/40\", host)\n",
    "        # url = to_url(path, None)\n",
    "        ftp_pos = tuple_['ome_zarr_path'].replace(\"/srv/brain-images/\", \"\")\n",
    "        url = \"https://neuroglancer-demo.appspot.com/#!%7B%22dimensions%22:%7B%22z%22:%5B0.05%2C%22m%22%5D%2C%22y%22:%5B0.00125%2C%22m%22%5D%2C%22x%22:%5B0.00125%2C%22m%22%5D%7D%2C%22position%22:%5B145.8433074951172%2C3059.48779296875%2C5833.75244140625%5D%2C%22crossSectionScale%22:24.02241726399886%2C%22projectionOrientation%22:%5B-0.14507155120372772%2C0.1366751343011856%2C0.03381236642599106%2C0.9793522953987122%5D%2C%22projectionScale%22:18598.1290980758%2C%22layers%22:%5B%7B%22type%22:%22image%22%2C%22source%22:%7B%22url%22:%22zarr://https://xulabtexera.anat.uci.edu/neuroglancer-ftp/\" + ftp_pos + \"%22%2C%22transform%22:%7B%22outputDimensions%22:%7B%22z%22:%5B0.05%2C%22m%22%5D%2C%22y%22:%5B0.00125%2C%22m%22%5D%2C%22x%22:%5B0.00125%2C%22m%22%5D%7D%2C%22inputDimensions%22:%7B%22z%22:%5B0.05%2C%22m%22%5D%2C%22y%22:%5B0.00125%2C%22m%22%5D%2C%22x%22:%5B0.00125%2C%22m%22%5D%7D%7D%7D%2C%22tab%22:%22source%22%2C%22opacity%22:0.4%2C%22shader%22:%22#uicontrol%20invlerp%20normalized%5Cnvoid%20main%28%29%20%7B%5Cn%20%20emitGrayscale%28normalized%28%29%29%3B%5Cn%7D%22%2C%22shaderControls%22:%7B%22normalized%22:%7B%22range%22:%5B0%2C2086%5D%7D%7D%2C%22name%22:%22ome.zarr_neuroglancer1%22%7D%5D%2C%22selectedLayer%22:%7B%22visible%22:true%2C%22layer%22:%22ome.zarr_neuroglancer1%22%7D%2C%22layout%22:%224panel%22%2C%22selection%22:%7B%7D%2C%22layerListPanel%22:%7B%22visible%22:true%7D%7D\"\n",
    "        yield {\"url\": url}\n",
    "\"\"\"\n",
    "\n",
    "def get_mm_dict(z_mm=0.00125*5, y_mm=0.00125, x_mm=0.00125):\n",
    "    \"\"\"\n",
    "    Return a dict used to generate the sizes of voxels in mm.\n",
    "    \"\"\"\n",
    "    return {\"z\": [float(z_mm*0.001), \"m\"],\n",
    "            \"y\": [float(y_mm*0.001), \"m\"],\n",
    "            \"x\": [float(x_mm*0.001), \"m\"]}\n",
    "\n",
    "\n",
    "def get_template_layer(\n",
    "        template_src,\n",
    "        mm_dict,\n",
    "        public_name=\"Template layer\",\n",
    "        is_uint=False):\n",
    "    \"\"\"\n",
    "    Return a dict containing configuration parameters for a grayscale\n",
    "    template image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    template_src:\n",
    "        URL-like location of the template image data. Assumes it is formatted\n",
    "        as an OME-ZARR dataset.\n",
    "\n",
    "    range_max:\n",
    "        The pixel intensity value that gets set to white in the grayscale image.\n",
    "\n",
    "    public_name:\n",
    "        Name of the template image that will appear in the visualization\n",
    "\n",
    "    is_uint:\n",
    "        Set to true if the image data is an unsigned integer (that has some\n",
    "        implications for the shader code used to control the color of\n",
    "        the image)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict of configuration parameters for the grayscale template image\n",
    "    \"\"\"\n",
    "    result = dict()\n",
    "    result[\"type\"] = \"image\"\n",
    "    # result[\"source\"] = f\"zarr://{template_src}\"\n",
    "    result[\"source\"] = {\"url\": f\"zarr://{template_src}\",\n",
    "                        \"transform\": {\n",
    "                            \"outputDimensions\": mm_dict,\n",
    "                            \"inputDimensions\": mm_dict\n",
    "                        }}\n",
    "    result[\"blend\"] = \"default\"\n",
    "    # result[\"shader\"] = get_grayscale_shader_code(\n",
    "    #                       transparent=False,\n",
    "    #                       range_max=range_max,\n",
    "    #                       is_uint=is_uint)\n",
    "    result[\"shader\"] = get_simple_grayscale_shader_code()\n",
    "    result[\"opacity\"] = 0.4\n",
    "    result[\"visible\"] = True\n",
    "    result[\"name\"] = public_name\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_grayscale_shader_code(\n",
    "        transparent=True,\n",
    "        range_max=20.0,\n",
    "        threshold=0.0,\n",
    "        is_uint=False):\n",
    "    \"\"\"\n",
    "    Get shader code for a grayscale image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transparent:\n",
    "        If True, voxels lower than threshold are transparent.\n",
    "        If False, voxels lower than threshold are black.\n",
    "\n",
    "    range_max:\n",
    "        Value that gets mapped to the maximum color intensity\n",
    "\n",
    "    threshold:\n",
    "        Value below which voxel is either transparent or black.\n",
    "\n",
    "    is_uint:\n",
    "        Set to true if the image data is an unsigned integer (that has some\n",
    "        implications for the shader code used to control the color of\n",
    "        the image)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A string representing the shader code for coloring the image.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    if transparent:\n",
    "        default = 'emitTransparent()'\n",
    "    else:\n",
    "        default = 'emitRGB(vec3(0, 0, 0))'\n",
    "\n",
    "    code = f\"#uicontrol invlerp normalized(range=[0,{range_max}])\\n\"\n",
    "    code += \"void main()\"\n",
    "    code += \" {\\n  \"\n",
    "    if is_uint:\n",
    "        code += f\"    if(int(getDataValue(0).value)>{int(threshold)})\"\n",
    "    else:\n",
    "        code += f\"    if(getDataValue(0)>{threshold})\"\n",
    "    code += \"{\\n\"\n",
    "    code += \"        emitGrayscale(normalized())\"\n",
    "    code += \";\\n}\"\n",
    "    code += \"    else{\\n\"\n",
    "    code += f\"{default}\"\n",
    "    code += \";}\\n}\"\n",
    "    return code\n",
    "\n",
    "\n",
    "def get_simple_grayscale_shader_code():\n",
    "    \"\"\"\n",
    "    Get shader code for a grayscale image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A string representing the shader code for coloring the image.\n",
    "    \"\"\"\n",
    "    code = f\"#uicontrol invlerp normalized\\n\"\n",
    "    code += \"void main()\"\n",
    "    code += \" {\\n  \"\n",
    "    code += \"emitGrayscale(normalized());\\n}\"\n",
    "    return code\n",
    "\n",
    "\n",
    "def get_base_url():\n",
    "    \"\"\"\n",
    "    Return the base URL of the neuroglancer instance that will be running\n",
    "    your visualization. Note: most of the work is actually done on the client\n",
    "    browser.\n",
    "    \"\"\"\n",
    "    return \"https://neuroglancer-demo.appspot.com/#!\"\n",
    "\n",
    "\n",
    "def json_to_url(json_data):\n",
    "    \"\"\"\n",
    "    Serialize the config dict into an HTML-compliant string.\n",
    "    \"\"\"\n",
    "    return urllib.parse.quote(json_data)\n",
    "\n",
    "\n",
    "def get_final_url(\n",
    "        image_layer_list,\n",
    "        template_layer=None,\n",
    "        segmentation_layer=None,\n",
    "        starting_position=None,\n",
    "        mm_dict=None,\n",
    "        projection_scale=2048,\n",
    "        cross_section_scale=2.6):\n",
    "    \"\"\"\n",
    "    Create a valid neuroglancer URL\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_layer_list:\n",
    "        A list of dicts. Each dict is the configuration for a different\n",
    "        image layer.\n",
    "\n",
    "    template_layer:\n",
    "        A dict containing the configuration for the template layer.\n",
    "        (if None, not included)\n",
    "\n",
    "    segmentation_layer:\n",
    "        A dict containing the configuration for the segmentation layer.\n",
    "        (if None, not included)\n",
    "\n",
    "    starting_position:\n",
    "        Optional (x, y, z) tuple of the voxel on which you want the\n",
    "        visualization to automatically load. If None, will use\n",
    "        neuroglancer's default.\n",
    "\n",
    "    x_mm, y_mm, z_mm:\n",
    "        (x, y, z) sizes of voxels in millimeters\n",
    "\n",
    "    projection_scale, cross_section_scale:\n",
    "        Scaling parameters for  visualization\n",
    "        (not actually sure what they represent)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A string containing a URL to a neuroglancer visualization\n",
    "    of the image layers you input.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(image_layer_list, list):\n",
    "        image_layer_list = [image_layer_list]\n",
    "\n",
    "    url = get_base_url()\n",
    "\n",
    "    layer_list = image_layer_list\n",
    "    if template_layer is not None:\n",
    "        layer_list.append(template_layer)\n",
    "    if segmentation_layer is not None:\n",
    "        layer_list.append(segmentation_layer)\n",
    "    if mm_dict is None:\n",
    "        mm_dict = get_mm_dict()\n",
    "\n",
    "    layers = dict()\n",
    "    layers[\"dimensions\"] = mm_dict\n",
    "    layers[\"crossSectionScale\"] = cross_section_scale\n",
    "    layers[\"projectionScale\"] = projection_scale\n",
    "    layers[\"layers\"] = layer_list\n",
    "    layers[\"selectedLayer\"] = {\"visible\": True, \"layer\": \"new layer\"}\n",
    "    layers[\"layout\"] = \"4panel\"\n",
    "\n",
    "    if starting_position is not None:\n",
    "        layers[\"position\"] = [float(x) for x in starting_position]\n",
    "    url = f\"{url}{json_to_url(json.dumps(layers))}\"\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[518  97 167]\n",
      " [503 103 196]\n",
      " [527 296 224]\n",
      " ...\n",
      " [158 197 230]\n",
      " [158 199 234]\n",
      " [158 201 231]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "output_indices = np.load(\"outputIndices.npy\")\n",
    "output_indices = output_indices[~np.all(output_indices == [0, 0, 0], axis=1)]\n",
    "\n",
    "print(output_indices)\n",
    "\n",
    "np.savetxt(\"outputIndices.txt\", output_indices , \"%d %d %d\", \n",
    "           header = \"index\\n\" + str(output_indices.shape[0]), \n",
    "           comments = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3016, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
